{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6WdkcmzF_w",
        "outputId": "194289ad-0016-457a-9654-d76ee2d396d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "headers = {\n",
        "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'\n",
        "}\n",
        "\n",
        "urls = [\n",
        "    'https://groww.in/us-stocks/nke',\n",
        "    'https://groww.in/us-stocks/ko',\n",
        "    'https://groww.in/us-stocks/msft',\n",
        "    'https://groww.in/stocks/m-india-ltd',\n",
        "    'https://groww.in/us-stocks/axp',\n",
        "    'https://groww.in/us-stocks/amgn',\n",
        "    'https://groww.in/us-stocks/aapl',\n",
        "    'https://groww.in/us-stocks/ba',\n",
        "    'https://groww.in/us-stocks/csco',\n",
        "    'https://groww.in/us-stocks/gs',\n",
        "    'https://groww.in/us-stocks/ibm',\n",
        "    'https://groww.in/us-stocks/intc',\n",
        "    'https://groww.in/us-stocks/jpm',\n",
        "    'https://groww.in/us-stocks/mcd',\n",
        "    'https://groww.in/us-stocks/crm',\n",
        "    'https://groww.in/us-stocks/vz',\n",
        "    'https://groww.in/us-stocks/v',\n",
        "    'https://groww.in/us-stocks/wmt',\n",
        "    'https://groww.in/us-stocks/dis'\n",
        "]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract stock details\n",
        "        company = soup.find('h1')\n",
        "        price = soup.find('span')\n",
        "        change = soup.find('div')\n",
        "        volume = soup.find('table')\n",
        "\n",
        "        # Handle missing data safely\n",
        "        company = company.get_text(strip=True) if company else \"N/A\"\n",
        "        price = price.get_text(strip=True) if price else \"N/A\"\n",
        "        change = change.get_text(strip=True) if change else \"N/A\"\n",
        "        volume = volume.get_text(strip=True) if volume else \"N/A\"\n",
        "\n",
        "        all_data.append([company, price, change, volume])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "\n",
        "    # Wait to avoid rate-limiting (randomized delay)\n",
        "    time.sleep(random.uniform(5, 10))\n",
        "\n",
        "# Creating DataFrame directly\n",
        "df = pd.DataFrame(all_data, columns=[\"Company\", \"Price\", \"Change\", \"Volume\"])\n",
        "\n",
        "# Save to Excel\n",
        "df.to_excel('stocks.xlsx', index=False)\n",
        "\n",
        "print(\"Scraping completed successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bGqoVlN9zGdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}